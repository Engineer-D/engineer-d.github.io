---
title: "Search-Augmented RL for Legal Reasoning"
---

## Overview

Research on interpretable legal reasoning using Search-Augmented Reinforcement Learning, conducted at Meridus Research Lab. This work combines retrieval-augmented generation with RL-based alignment techniques to produce reliable, citation-grounded legal analysis.

## Research Contributions

### Alignment Techniques
- **DPO (Direct Preference Optimization)**: Preference-based alignment without explicit reward models
- **GRPO (Group Relative Policy Optimization)**: Efficient policy optimization with group-level reward signals
- **PPO (Proximal Policy Optimization)**: Standard RL fine-tuning with advantage estimation for stable training

### Search Augmentation
Integrating retrieval into the RL loop â€” the model learns not just what to generate, but when and how to search for supporting evidence, improving both accuracy and interpretability.

## Key Insight

Legal reasoning requires models that can cite sources, explain logic chains, and hedge appropriately. By combining search augmentation with RL alignment, we produce outputs that are both more accurate and more trustworthy than standard RAG approaches.

## Ongoing Work

This research continues with exploration of constitutional AI approaches for domain-specific safety constraints and multi-step reasoning verification.
