1:"$Sreact.fragment"
2:I[22016,["/_next/static/chunks/ea8e777f55f34255.js"],""]
5:I[97367,["/_next/static/chunks/ff1a16fafef87110.js","/_next/static/chunks/d2be314c3ece3fbe.js"],"OutletBoundary"]
6:"$Sreact.suspense"
0:{"buildId":"iWPBSXllpM2sklPV5P5lP","rsc":["$","$1","c",{"children":[["$","div",null,{"className":"max-w-3xl mx-auto px-4 sm:px-6 pt-12 pb-20","children":[["$","$L2",null,{"href":"/projects","className":"inline-flex items-center gap-1 text-sm text-muted hover:text-foreground transition-colors mb-8","children":[["$","svg",null,{"xmlns":"http://www.w3.org/2000/svg","width":14,"height":14,"viewBox":"0 0 24 24","fill":"none","stroke":"currentColor","strokeWidth":2,"strokeLinecap":"round","strokeLinejoin":"round","className":"lucide lucide-arrow-left","aria-hidden":"true","children":[["$","path","1l729n",{"d":"m12 19-7-7 7-7"}],["$","path","x3x0zl",{"d":"M19 12H5"}],"$undefined"]}]," Back to Projects"]}],["$","div",null,{"className":"flex items-center gap-3 mb-4","children":[["$","span",null,{"className":"text-xs px-2.5 py-1 rounded-full border bg-purple-500/10 text-purple-400 border-purple-500/20","children":"Research"}],["$","span",null,{"className":"text-sm text-muted","children":"2024–Present"}]]}],["$","h1",null,{"className":"text-3xl sm:text-4xl font-bold tracking-tight mb-4","children":"Search-Augmented RL for Legal Reasoning"}],["$","p",null,{"className":"text-lg text-muted leading-relaxed mb-6","children":"Research on interpretable legal reasoning using Search-Augmented Reinforcement Learning with DPO, GRPO, and PPO for LLM alignment in specialized domains."}],["$","div",null,{"className":"flex flex-wrap gap-2 mb-6","children":[["$","span","RL",{"className":"text-xs px-2.5 py-1 rounded-md bg-tag-bg text-tag-text","children":"RL"}],["$","span","DPO",{"className":"text-xs px-2.5 py-1 rounded-md bg-tag-bg text-tag-text","children":"DPO"}],["$","span","GRPO",{"className":"text-xs px-2.5 py-1 rounded-md bg-tag-bg text-tag-text","children":"GRPO"}],["$","span","PPO",{"className":"text-xs px-2.5 py-1 rounded-md bg-tag-bg text-tag-text","children":"PPO"}],["$","span","LLM Alignment",{"className":"text-xs px-2.5 py-1 rounded-md bg-tag-bg text-tag-text","children":"LLM Alignment"}],["$","span","Research",{"className":"text-xs px-2.5 py-1 rounded-md bg-tag-bg text-tag-text","children":"Research"}]]}],"$undefined",["$","article",null,{"className":"prose prose-invert max-w-none prose-headings:font-semibold prose-a:text-accent prose-a:no-underline hover:prose-a:underline","children":[["$","h2",null,{"children":"Overview"}],"\n",["$","p",null,{"children":"Research on interpretable legal reasoning using Search-Augmented Reinforcement Learning, conducted at Meridus Research Lab. This work combines retrieval-augmented generation with RL-based alignment techniques to produce reliable, citation-grounded legal analysis."}],"\n",["$","h2",null,{"children":"Research Contributions"}],"\n",["$","h3",null,{"children":"Alignment Techniques"}],"\n",["$","ul",null,{"children":["\n",["$","li",null,{"children":[["$","strong",null,{"children":"DPO (Direct Preference Optimization)"}],": Preference-based alignment without explicit reward models"]}],"\n",["$","li",null,{"children":[["$","strong",null,{"children":"GRPO (Group Relative Policy Optimization)"}],": Efficient policy optimization with group-level reward signals"]}],"\n",["$","li",null,{"children":[["$","strong",null,{"children":"PPO (Proximal Policy Optimization)"}],": Standard RL fine-tuning with advantage estimation for stable training"]}],"\n"]}],"\n",["$","h3",null,{"children":"Search Augmentation"}],"\n",["$","p",null,{"children":"Integrating retrieval into the RL loop — the model learns not just what to generate, but when and how to search for supporting evidence, improving both accuracy and interpretability."}],"\n",["$","h2",null,{"children":"Key Insight"}],"\n",["$","p",null,{"children":"Legal reasoning requires models that can cite sources, explain logic chains, and hedge appropriately. By combining search augmentation with RL alignment, we produce outputs that are both more accurate and more trustworthy than standard RAG approaches."}],"\n",["$","h2",null,{"children":"Ongoing Work"}],"\n","$L3"]}]]}],null,"$L4"]}],"loading":null,"isPartial":false}
3:["$","p",null,{"children":"This research continues with exploration of constitutional AI approaches for domain-specific safety constraints and multi-step reasoning verification."}]
4:["$","$L5",null,{"children":["$","$6",null,{"name":"Next.MetadataOutlet","children":"$@7"}]}]
7:null
